# Project: Implementing Data Warehouses on AWS
In this project, I build an ETL pipeline for a Sparkify music database hosted on Redshift. The ETL pipeline extracts data from S3, stages data on Redshift, and transforms data into dimensional tables for analytics.

## Project Structure

1. `create _tables.py` - Drop and create all tables.
2. `dwh.cfg` - Config file for AWS setup.
3. `etl.py` - Extracts data from S3, stages data on Redshift, and transforms data into dimensional tables for analytics.
4. `sql_queries.py` - This script contains all sql statements that go on to create the tables, extract the data from redshift, load into staging tables and insert into the final tables. 
5. `IaC.ipynb` - Create Redshift Cluster using the AWS python SDK. This file also contains test code.

## Datasets

### Song Dataset

The first dataset is a subset of real data from the [Million Song Dataset](http://millionsongdataset.com/). Each file is in JSON format and contains metadata about a song and the artist of that song. The files are partitioned by the first three letters of each song's track ID.

And below is an example of what a single song file, TRAABJL12903CDCF1A.json, looks like:
```
{"num_songs": 1, "artist_id": "ARJIE2Y1187B994AB7", "artist_latitude": null, "artist_longitude": null, "artist_location": "", "artist_name": "Line Renaud", "song_id": "SOUPIRU12A6D4FA1E1", "title": "Der Kleine Dompfaff", "duration": 152.92036, "year": 0}
```

This dataset is hosted in S3: 

```
s3://udacity-dend/song_data
```

### Log Dataset 

The second dataset consists of log files in JSON format generated by this [event simulator](https://github.com/Interana/eventsim) based on the songs in the dataset above. These simulate app activity logs from an imaginary music streaming app based on configuration settings.

```
s3://udacity-dend/log_data
```

## Database Schema

### Staging tables
```
staging_events
    artist varchar,
    auth varchar,
    firstName varchar,
    gender char(1),
    itemInSession smallint,
    lastName varchar,
    length float,
    level varchar,
    location varchar,
    method varchar,
    page varchar,
    registration bigint,
    sessionId int,
    song varchar,
    status smallint,
    ts bigint,
    userAgent varchar,
    userId int
    
staging_songs
    num_songs int,
    artist_id varchar,
    artist_latitude float,
    artist_longitude float,
    artist_location varchar,
    artist_name varchar,
    song_id varchar,
    title varchar,
    duration float,
    year smallint
```

### Fact table
```
fact_songplays
    songplay_id int identity(0,1) primary key,
    start_time timestamp references dim_time (start_time),
    user_id int references dim_users (user_id),
    level varchar,
    song_id varchar references dim_songs (song_id),
    artist_id varchar references dim_artists (artist_id),
    session_id int, 
    location varchar, 
    user_agent varchar
```

### Dimension tables
```
dim_users
    user_id int primary key, 
    first_name varchar, 
    last_name varchar, 
    gender char(1), 
    level varchar
    
dim_songs
    song_id varchar primary key, 
    title varchar, 
    artist_id varchar not null, 
    year smallint, 
    duration float

dim_artists
    artist_id varchar primary key,  
    name varchar not null, 
    location varchar, 
    latitude float, 
    longitude float

dim_time
    start_time timestamp primary key, 
    hour smallint not null, 
    day smallint not null, 
    week smallint not null, 
    month smallint not null, 
    year smallint not null, 
    weekday smallint not null
```